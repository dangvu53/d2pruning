{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6bd4481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.4-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./.venv/lib/python3.10/site-packages (from evaluate) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from evaluate) (2.2.6)\n",
      "Requirement already satisfied: dill in ./.venv/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from evaluate) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.10/site-packages (from evaluate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.venv/lib/python3.10/site-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.10/site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in ./.venv/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./.venv/lib/python3.10/site-packages (from evaluate) (0.33.1)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from evaluate) (25.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in ./.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (20.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./.venv/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in ./.venv/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.4-py3-none-any.whl (84 kB)\n",
      "Installing collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install evaluate library for load_metric function\n",
    "%pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "919ad982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Using cached accelerate-1.8.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./.venv/lib/python3.10/site-packages (from accelerate) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./.venv/lib/python3.10/site-packages (from accelerate) (2.7.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in ./.venv/lib/python3.10/site-packages (from accelerate) (0.33.1)\n",
      "Collecting safetensors>=0.4.3 (from accelerate)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in ./.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3.1)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./.venv/lib/python3.10/site-packages (from triton==3.3.1->torch>=2.0.0->accelerate) (59.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.6.15)\n",
      "Using cached accelerate-1.8.1-py3-none-any.whl (365 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Installing collected packages: safetensors, accelerate\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [accelerate]2\u001b[0m [accelerate]\n",
      "\u001b[1A\u001b[2KSuccessfully installed accelerate-1.8.1 safetensors-0.5.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abf0b40",
   "metadata": {},
   "source": [
    "Run on ANLI-2k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7547d078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google-bert/bert-base-uncased'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"google/electra-small-discriminator\"\n",
    "\"FacebookAI/roberta-base\"\n",
    "\"google-bert/bert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb280e3",
   "metadata": {},
   "source": [
    "Train on full to get training dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71668ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "%cd d2pruning/\n",
    "!python train_nlp_explore.py \\\n",
    "    --task_name \"goddawg/anli-2k\" \\\n",
    "    --model_name_or_path \"google/electra-small-discriminator\" \\\n",
    "    --output_dir ./data-model/anli-2k/all-data \\\n",
    "    --do_train \\\n",
    "    --do_test \\\n",
    "    --train_logger \\\n",
    "    --num_train_epochs 10 \\\n",
    "    --per_device_train_batch_size 16 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --max_length 256 \\\n",
    "    --val-index-path ./data-model/anli-2k/val_index.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38710cc",
   "metadata": {},
   "source": [
    "Save feature embeddings and importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aec4363",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd d2pruning/\n",
    "!python train_nlp_explore.py \\\n",
    "    --task_name \"goddawg/anli-2k\" \\\n",
    "    --model_name_or_path roberta-base \\\n",
    "    --output_dir ./data-model/anli-2k/all-data \\\n",
    "    --do_eval \\\n",
    "    --eval_train \\\n",
    "    --save_feature \\\n",
    "    --save_confidence \\\n",
    "    --save_importance_scores \\\n",
    "    --training_dynamics \\\n",
    "    --per_device_eval_batch_size 16 \\\n",
    "    --max_length 256 \\\n",
    "    --val-index-path ./data-model/anli-2k/val_index.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9288b5c3",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "Prun and train on 50% data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459148a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORESET_RATIO = 0.5\n",
    "N_NEIGHBOR = 10\n",
    "GAMMA = 0.1\n",
    "\n",
    "%cd d2pruning/\n",
    "!python train_nlp_explore.py \\\n",
    "    --task_name \"goddawg/anli-2k\" \\\n",
    "    --model_name_or_path roberta-base \\\n",
    "    --output_dir ./data-model/anli-2k/coreset-0.5 \\\n",
    "    --do_train \\\n",
    "    --do_test \\\n",
    "    --coreset \\\n",
    "    --coreset-mode class \\\n",
    "    --budget-mode uniform \\\n",
    "    --sampling-mode graph \\\n",
    "    --data-score-path ./data-model/anli-2k/all-data/data-score-goddawg.pickle \\\n",
    "    --feature-path ./data-model/anli-2k/all-data/train-features.npy \\\n",
    "    --coreset-key forgetting \\\n",
    "    --coreset-ratio {CORESET_RATIO} \\\n",
    "    --mis-ratio 0.4 \\\n",
    "    --label-balanced \\\n",
    "    --num_train_epochs 10 \\\n",
    "    --per_device_train_batch_size 32 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --max_length 256 \\\n",
    "    --val-index-path ./data-model/anli-2k/val_index.npy \\\n",
    "    --n-neighbor {N_NEIGHBOR} \\\n",
    "    --gamma {GAMMA} \\\n",
    "    --graph-mode sum \\\n",
    "    --graph-sampling-mode weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888302e0",
   "metadata": {},
   "source": [
    "Train D(Full data) and D'(50% coreset) on BERT base uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ff245",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd d2pruning/\n",
    "!python train_nlp_explore.py \\\n",
    "    --task_name \"goddawg/anli-2k\" \\\n",
    "    --model_name_or_path bert-base-uncased \\\n",
    "    --output_dir ./data-model/anli-2k/roberta_base/bert/ \\\n",
    "    --do_train \\\n",
    "    --do_test \\\n",
    "    --train_logger \\\n",
    "    --num_train_epochs 10 \\\n",
    "    --per_device_train_batch_size 16 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --max_length 256 \\\n",
    "    --val-index-path ./data-model/anli-2k/val_index.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda05b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd d2pruning/\n",
    "!python train_nlp_explore.py \\\n",
    "    --task_name \"goddawg/anli-2k\" \\\n",
    "    --model_name_or_path bert-base-uncased \\\n",
    "    --output_dir ./data-model/anli-2k/roberta_base/bert-50%/ \\\n",
    "    --do_train \\\n",
    "    --do_test \\\n",
    "    --train_logger \\\n",
    "    --num_train_epochs 10 \\\n",
    "    --per_device_train_batch_size 16 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --max_length 256 \\\n",
    "    --val-index-path ./data-model/anli-2k/val_index.npy \\\n",
    "    --train-index-path ./data-model/anli-2k/roberta_base/coreset-50%/coreset-goddawg.npy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e9fb3b",
   "metadata": {},
   "source": [
    "### Run on AGNews-5K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "331492c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.venv/lib/python3.10/site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eded826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from datasets) (2.2.6)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in ./.venv/lib/python3.10/site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in ./.venv/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in ./.venv/lib/python3.10/site-packages (from datasets) (0.33.1)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading multidict-6.6.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (73 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in ./.venv/lib/python3.10/site-packages (from multidict<7.0,>=4.5->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.0 in ./.venv/lib/python3.10/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.10)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in ./.venv/lib/python3.10/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2025.6.15)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
      "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading aiohttp-3.12.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading multidict-6.6.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (242 kB)\n",
      "Downloading yarl-1.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.7.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (222 kB)\n",
      "Downloading propcache-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (198 kB)\n",
      "Downloading pyarrow-20.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "Installing collected packages: xxhash, pyarrow, propcache, multidict, fsspec, frozenlist, dill, attrs, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, aiohttp, datasets\n",
      "\u001b[2K  Attempting uninstall: fsspec\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [multidict]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [multidict]\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [multidict]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/15\u001b[0m [multidict]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/15\u001b[0m [datasets]/15\u001b[0m [datasets]]ss]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.13 aiosignal-1.3.2 async-timeout-5.0.1 attrs-25.3.0 datasets-3.6.0 dill-0.3.8 frozenlist-1.7.0 fsspec-2025.3.0 multidict-6.6.1 multiprocess-0.70.16 propcache-0.3.2 pyarrow-20.0.0 xxhash-3.5.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02b6349d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'google-bert/bert-base-uncased'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"google/electra-small-discriminator\"\n",
    "\"FacebookAI/roberta-base\"\n",
    "\"google-bert/bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9236ad3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'd2pruning/'\n",
      "/drive1/nammt/d2pruning\n",
      "06/28/2025 16:49:36 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: no\n",
      "\n",
      "Loading validation set from saved index\n",
      "Reduced training set from 6000 to 5000 for creating validation set\n",
      "/drive1/nammt/d2pruning/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/automl/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google-bert/bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"goddawg/agnews-6k\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/automl/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google-bert/bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/automl/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/automl/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/automl/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/automl/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"google-bert/bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/automl/.cache/huggingface/hub/models--google-bert--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Running tokenizer on dataset: 100%|█| 5000/5000 [00:00<00:00, 8997.58 examples/s\n",
      "Running tokenizer on dataset: 100%|█| 1000/1000 [00:00<00:00, 8883.00 examples/s\n",
      "Running tokenizer on dataset: 100%|█| 1000/1000 [00:00<00:00, 8694.88 examples/s\n",
      "06/28/2025 16:49:45 - INFO - __main__ - Sample 912 of the training set: (912, {'input_ids': [101, 3956, 1005, 1055, 10666, 3210, 2039, 2490, 2005, 5622, 5283, 2094, 3789, 102, 6744, 1006, 26665, 1007, 1011, 5611, 3539, 2704, 16126, 10666, 8610, 2098, 2490, 2005, 9432, 1005, 1055, 5622, 5283, 2094, 2283, 3789, 2000, 3288, 1996, 4450, 2283, 2046, 1037, 2231, 2008, 2052, 3796, 10245, 3864, 1998, 6643, 3726, 1996, 2126, 2005, 1037, 14474, 10534, 2279, 2095, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 0}).\n",
      "06/28/2025 16:49:45 - INFO - __main__ - Sample 204 of the training set: (204, {'input_ids': [101, 13420, 6971, 2039, 2007, 25353, 14905, 2937, 102, 2044, 3773, 2210, 3112, 2007, 1996, 4431, 5617, 2009, 2580, 2005, 7513, 1001, 4464, 1025, 1055, 26381, 4132, 1010, 13420, 2097, 2085, 2147, 2007, 25353, 14905, 2937, 2000, 3443, 4431, 7248, 2005, 1017, 2290, 2398, 8454, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 3}).\n",
      "06/28/2025 16:49:45 - INFO - __main__ - Sample 2253 of the training set: (2253, {'input_ids': [101, 4654, 3540, 22879, 5668, 7523, 2322, 12954, 28397, 1999, 5279, 1006, 9706, 1007, 102, 9706, 1011, 4654, 3540, 22879, 5668, 3603, 2322, 23880, 12954, 28397, 1999, 1996, 13253, 3089, 3148, 18128, 1999, 2530, 5279, 1010, 1996, 2231, 1005, 1055, 2473, 1997, 21387, 2056, 9857, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': 3}).\n",
      "Downloading builder script: 4.20kB [00:00, 5.97MB/s]\n",
      "06/28/2025 16:49:48 - INFO - __main__ - ***** Running training *****\n",
      "06/28/2025 16:49:48 - INFO - __main__ -   Num examples = 5000\n",
      "06/28/2025 16:49:48 - INFO - __main__ -   Num Epochs = 10\n",
      "06/28/2025 16:49:48 - INFO - __main__ -   Instantaneous batch size per device = 16\n",
      "06/28/2025 16:49:48 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "06/28/2025 16:49:48 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "06/28/2025 16:49:48 - INFO - __main__ -   Total optimization steps = 3130\n",
      "  0%|                                                  | 0/3130 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      " 10%|███▉                                    | 312/3130 [00:43<06:39,  7.05it/s]06/28/2025 16:50:35 - INFO - __main__ - epoch 0: validation: {'accuracy': 0.896}\n",
      "epoch 0: validation: {'accuracy': 0.896}\n",
      "06/28/2025 16:50:38 - INFO - __main__ - epoch 0: test: {'accuracy': 0.906}\n",
      "epoch 0: test: {'accuracy': 0.906}\n",
      " 20%|████████                                | 626/3130 [01:34<05:07,  8.13it/s]06/28/2025 16:51:25 - INFO - __main__ - epoch 1: validation: {'accuracy': 0.895}\n",
      "epoch 1: validation: {'accuracy': 0.895}\n",
      "06/28/2025 16:51:28 - INFO - __main__ - epoch 1: test: {'accuracy': 0.897}\n",
      "epoch 1: test: {'accuracy': 0.897}\n",
      " 30%|████████████                            | 939/3130 [02:25<04:57,  7.36it/s]06/28/2025 16:52:16 - INFO - __main__ - epoch 2: validation: {'accuracy': 0.904}\n",
      "epoch 2: validation: {'accuracy': 0.904}\n",
      "06/28/2025 16:52:19 - INFO - __main__ - epoch 2: test: {'accuracy': 0.903}\n",
      "epoch 2: test: {'accuracy': 0.903}\n",
      " 40%|███████████████▌                       | 1252/3130 [03:17<04:42,  6.64it/s]06/28/2025 16:53:08 - INFO - __main__ - epoch 3: validation: {'accuracy': 0.91}\n",
      "epoch 3: validation: {'accuracy': 0.91}\n",
      "06/28/2025 16:53:11 - INFO - __main__ - epoch 3: test: {'accuracy': 0.907}\n",
      "epoch 3: test: {'accuracy': 0.907}\n",
      " 50%|███████████████████▌                   | 1565/3130 [04:08<03:13,  8.08it/s]06/28/2025 16:53:59 - INFO - __main__ - epoch 4: validation: {'accuracy': 0.905}\n",
      "epoch 4: validation: {'accuracy': 0.905}\n",
      "06/28/2025 16:54:02 - INFO - __main__ - epoch 4: test: {'accuracy': 0.916}\n",
      "epoch 4: test: {'accuracy': 0.916}\n",
      " 60%|███████████████████████▍               | 1877/3130 [05:00<03:07,  6.67it/s]06/28/2025 16:54:51 - INFO - __main__ - epoch 5: validation: {'accuracy': 0.9}\n",
      "epoch 5: validation: {'accuracy': 0.9}\n",
      "06/28/2025 16:54:54 - INFO - __main__ - epoch 5: test: {'accuracy': 0.912}\n",
      "epoch 5: test: {'accuracy': 0.912}\n",
      " 70%|███████████████████████████▎           | 2191/3130 [05:51<02:15,  6.91it/s]06/28/2025 16:55:42 - INFO - __main__ - epoch 6: validation: {'accuracy': 0.907}\n",
      "epoch 6: validation: {'accuracy': 0.907}\n",
      "06/28/2025 16:55:45 - INFO - __main__ - epoch 6: test: {'accuracy': 0.918}\n",
      "epoch 6: test: {'accuracy': 0.918}\n",
      " 80%|███████████████████████████████▏       | 2504/3130 [06:43<01:17,  8.04it/s]06/28/2025 16:56:34 - INFO - __main__ - epoch 7: validation: {'accuracy': 0.907}\n",
      "epoch 7: validation: {'accuracy': 0.907}\n",
      "06/28/2025 16:56:37 - INFO - __main__ - epoch 7: test: {'accuracy': 0.918}\n",
      "epoch 7: test: {'accuracy': 0.918}\n",
      " 90%|███████████████████████████████████    | 2817/3130 [07:35<00:41,  7.53it/s]06/28/2025 16:57:26 - INFO - __main__ - epoch 8: validation: {'accuracy': 0.906}\n",
      "epoch 8: validation: {'accuracy': 0.906}\n",
      "06/28/2025 16:57:29 - INFO - __main__ - epoch 8: test: {'accuracy': 0.918}\n",
      "epoch 8: test: {'accuracy': 0.918}\n",
      "100%|███████████████████████████████████████| 3130/3130 [08:27<00:00,  7.98it/s]06/28/2025 16:58:18 - INFO - __main__ - epoch 9: validation: {'accuracy': 0.908}\n",
      "epoch 9: validation: {'accuracy': 0.908}\n",
      "06/28/2025 16:58:21 - INFO - __main__ - epoch 9: test: {'accuracy': 0.917}\n",
      "epoch 9: test: {'accuracy': 0.917}\n",
      "100%|███████████████████████████████████████| 3130/3130 [08:34<00:00,  6.08it/s]\n"
     ]
    }
   ],
   "source": [
    "%cd d2pruning/\n",
    "!python train_nlp_explore.py \\\n",
    "    --task_name \"goddawg/agnews-6k\" \\\n",
    "    --model_name_or_path \"google-bert/bert-base-uncased\" \\\n",
    "    --output_dir ./data-model/agnews-6k/all-data \\\n",
    "    --do_train \\\n",
    "    --do_test \\\n",
    "    --train_logger \\\n",
    "    --num_train_epochs 10 \\\n",
    "    --per_device_train_batch_size 16 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --max_length 256 \\\n",
    "    --val-index-path ./data-model/agnews-6k//val_index.npy \\\n",
    "    --seed 42 \\\n",
    "    --data_seed 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86738bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
